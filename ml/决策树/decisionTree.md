#决策树


1、决策树概念：

熵：衡量信息不确定性的指标

信息熵：仅仅使用一元模型中的不确定指标

条件熵：一个事件的发生会依赖于其他条件的，信息越多，不确定性就越小

互信息： 值越大表示信息越相关

决策树由 决策节点(最优特征列) 分支(列的值) 叶子节点(最终选择的结果)

构建决策树的步骤：

1、计算出整个数据集的信息熵，此时为一维的熵

2、分割数据集，可以排除掉某列，并且为特定值以后组成新的一个数据集

3、选择出最佳特征列， 通过 互信息Gain = 信息熵-联合概率*条件熵 值越大表示该列和当前标签发生的事件越相关

4、当不断的分割后，最终只剩下一个当前标签列时，计算出该列不通值出现的概率，返回概率大的值

5、根据样本数据递归创建决策树

6、提供一个聚类方法，通过输入某条数据，根据构建的决策树的每个分支流向到子节点也就是一个最后的决策

参考：[决策树分类和预测算法的原理及实现](http://bluewhale.cc/2016-03-20/decision-tree.html#ixzz5BEsAFLNO)；

